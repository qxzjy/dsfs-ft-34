{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Tools & Agents\n",
    "\n",
    "## What you will learn in this course? üßêüßê\n",
    "\n",
    "Generating text is pretty powerful but it becomes really impressive when actions are triggered based on what was generated üòâ This is called **Agents**. These are actionable python functions that will know what actions are expected based on what an LLM generated. Combined with Langchain **Tools** it becomes really powerful because you will be able to run internet searches, use a code interpreter etc. In this course, you will learn:\n",
    "\n",
    "- LangGraph node and edges\n",
    "- Langchain tools\n",
    "- How to create simple and start-of-the-art agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Note type=\"important\">\n",
    "\n",
    "If you want to follow along, again use:\n",
    "\n",
    "```bash\n",
    "docker run -v $(pwd):/home/jovyan -p 8888:8888 jupyter/datascience-notebook\n",
    "```\n",
    "\n",
    "You will have a Jupyter Notebook ready to use\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If that's not the case, don't forget to install the following libraries\n",
    "!pip install langchain -q\n",
    "!pip install langchain-community -q \n",
    "!pip install langchain_mistralai -q\n",
    "!pip install langserve -q\n",
    "!pip install langgraph -q\n",
    "!pip install transformers -q\n",
    "!pip install rizaio -q \n",
    "!pip install --upgrade typing_extensions -q # If you have errors like \"cannot import name 'ReadOnly' from 'typing_extensions'\" DON'T FORGET TO RESTART YOUR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Mistral API key \n",
    "#%env MISTRAL_API_KEY="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo app üéÆ\n",
    "\n",
    "For this course, we will aim to build a chatbot that includes a **code interpreter**. This would make a perfect developer assistant! Let's see how we can set it up. First, let's have some basic code template:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "# Create our LLM\n",
    "llm = ChatMistralAI(model=\"ministral-8b-latest\")\n",
    "\n",
    "# LangGraph uses the concepts of graphs which corresponds to a workflow\n",
    "# The first thing you need to do is to instanciate that graph using StateGraph.\n",
    "# StateGraph needs to be provided a schema meaning the data it is expected to handle that is called states\n",
    "# A State corresponds to the data stored at a given moment in your graph as well as functions (called \"reducers\")\n",
    "# which purpose is to update the State.\n",
    "# In our case, we use MessagesState which is pre-configured State meant for messages\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Let's create a simple model with a system prompt\n",
    "def call_model(state: MessagesState):\n",
    "    # Intanciate the system prompt\n",
    "    start_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a protocol droid designed for assisting sentient beings in writing code.\"\n",
    "            ),\n",
    "            MessagesPlaceholder(\n",
    "                \"messages\"\n",
    "            ),  # This is where the additional messages will be added\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Chain the system prompt with Mistral LLM model\n",
    "    model = start_prompt | llm\n",
    "\n",
    "    # Here we need to provide a dictionnary with all the messages\n",
    "    response = model.invoke({\"messages\": state[\"messages\"]})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# This part defines a single node and an edge\n",
    "# an Edge is simply the \"how\" we get from one node to the other one\n",
    "# I like LangGraph short definition: \"nodes do the work. edges tell what to do next.\"\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# This is stored in RAM of the computer.\n",
    "# This is not ideal for production and large conversation history where you will need to define a PostgreSQL DB (more on the later on)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Store the whole graph\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# Display our current graph's schema\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is the exact same code as in the previous lecture where we have:\n",
    "\n",
    "- One \"start\" node\n",
    "- One edge going from start to \"model\" node\n",
    "- One \"model\" node that holds our chatbot\n",
    "\n",
    "Let's create a basic interaction to verify that everything works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! In Python, you can perform arithmetic operations using the `+` operator. Here is how you can calculate `3 + 5`:\n",
      "\n",
      "```python\n",
      "result = 3 + 5\n",
      "print(result)\n",
      "```\n",
      "\n",
      "When you run this code, it will output:\n",
      "\n",
      "```\n",
      "8\n",
      "```\n",
      "\n",
      "So, `3 + 5` equals `8` in Python.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configure a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# Simply query\n",
    "query = \"Can you tell me what is 3+5 using Python?\"\n",
    "\n",
    "# Parse the message into an acceptable data type for our model. In our case, the model accepts list of messages\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# Now the new element when calling \".invoke()\" is to add a config parameter to add the memory\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][\n",
    "    -1\n",
    "].pretty_print()  # output contains all messages in state so we take only the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate Tools in our application\n",
    "\n",
    "Many AI applications interact directly with humans. In these cases, it is appropriate for models to respond in natural language. But what about cases where we want a model to also interact directly with systems, such as databases or an API? These systems often have a particular input schema; for example, APIs frequently have a required payload structure. This need motivates the concept of tool calling. You can use tool calling to request model responses that match a particular schema.\n",
    "\n",
    "Here's a schema taken from langchain's documentation to illustrate how tools work:\n",
    "\n",
    "![tools](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/M10-llm/tool_calling_components-bef9d2bcb9d3706c2fe58b57bf8ccb60.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "[]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (hAwYuFd8K)\n",
      " Call ID: hAwYuFd8K\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'hAwYuFd8K', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "result1 = llm_with_tools.invoke(\"Hello world!\")\n",
    "result1.pretty_print()\n",
    "print(result1.tool_calls)\n",
    "result2 = llm_with_tools.invoke(\"What is 2 multiplied by 3?\")\n",
    "result2.pretty_print()\n",
    "print(result2.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the model understands that we ask it to perform a mathematic operation, it detects inputs a, and b, and uses the provided tool instead of relying solely on its NLP capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool for code execution\n",
    "\n",
    "Alright let's spice it up a little bit üå∂Ô∏è Now we want to add code interpreter that is able to actually run python code. To do se we will be using a [LangChain integrated tool]() called Riza\n",
    "\n",
    "Now the first action we need to do is to:\n",
    "\n",
    "- [Create an account on Riza](https://riza.io/) - This is a code interpreter tool\n",
    "  - This is completely free and the cool thing is that you can self host the code interpreter ü§ó\n",
    "\n",
    "<Note type=\"important\" title=\"Riza is limited as of today\">\n",
    "\n",
    "For this course we chose to have a free tool to play with. However, this is pretty new technology so there are a lot development going on and limitations.\n",
    "\n",
    "So far we know that:\n",
    "\n",
    "- Riza **cannot integrate pandas** as library\n",
    "\n",
    "If you are looking to implement a 100% robust code interpreter, you will need to either:\n",
    "\n",
    "- Build it yourself\n",
    "- Use a paid tool like [Azure Container Apps dynamic sessions](https://python.langchain.com/docs/integrations/tools/azure_dynamic_sessions/)\n",
    "\n",
    "</Note>\n",
    "\n",
    "<Note type=\"warning\" title=\"Tool usage is model dependent\">\n",
    "\n",
    "The model will decide whether to use the provided tools or not. For instance most light weight models have rather simplistic or unpredictable behavior. If the tools you provided are ignored when you thought they should not be, switch to a more complex model.\n",
    "\n",
    "Example: switch from `\"mistral-small-latest\"` to `\"mistral-large-latest\"`\n",
    "\n",
    "</Note>\n",
    "\n",
    "Once you created your account, get your API key and set it up as environment variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API key directly here: https://dashboard.riza.io/\n",
    "#%env RIZA_API_KEY="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now we can use LangChain tools to create awesome AI applications! To do so we need to:\n",
    "\n",
    "- Create and integrate a tool within our ChatModel\n",
    "- Then create an agent that will know when to use the tool or just leave that way.\n",
    "\n",
    "Let's tackle the first part:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'riza_exec_python', 'args': {'code': 'import pandas as pd'}, 'id': 'q1IozdcVC', 'type': 'tool_call'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  riza_exec_python (q1IozdcVC)\n",
      " Call ID: q1IozdcVC\n",
      "  Args:\n",
      "    code: import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Let's import ExecPython which is the class used to execute python code with Riza\n",
    "from langchain_community.tools.riza.command import ExecPython\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-large-latest\"\n",
    ")  # You can use whatever chat model you want here\n",
    "\n",
    "tools = [\n",
    "    ExecPython()\n",
    "]  # Let's intanciate ExecPython and it needs to be an item of a list\n",
    "powered_llm = llm.bind_tools(\n",
    "    tools\n",
    ")  # Integrate the tool within our LLm via bind_tools() method. Again careful, this methods accepts lists only (even if you have one tool)\n",
    "\n",
    "# Now lets use our tool!\n",
    "# Now given the prompt you write, the model will decide whether it's a good idea or not to \"call\" the tool\n",
    "# You can verify that the tool has been called by using .tool_calls attribute\n",
    "# Careful .tool_calls is not always available for all chat models.\n",
    "# It will be for any models that follow the OpenAI api structure of their model (Mistral does)\n",
    "result = powered_llm.invoke(\n",
    "    \"Execute this python code: ```python import pandas as pd```\"\n",
    ")\n",
    "\n",
    "print(result.tool_calls)\n",
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect as you can see, with `.bind_tools()` method we can integrate a tool within our LLM. Now for every prompt sent to the model, it will determine whether to call the tool or not.\n",
    "\n",
    "If you want to verify that a tool has been called, you can use `.tool_calls`.\n",
    "\n",
    "<Note type=\"note\">\n",
    "\n",
    "Careful `.tool_calls` is not always available for all chat models.\n",
    "It will be for any models that follow the OpenAI api structure of their model (Mistral does)\n",
    "\n",
    "</Note>\n",
    "\n",
    "<Note type=\"tip\" title=\"Still don't understand what tools are\">\n",
    "\n",
    "Think of tools as python functions (which they actually are). The only \"weird\" thing is that calling the tool is not always certain.\n",
    "\n",
    "For example, one model will want to call the code interpreter tool for any python code it sees (this will often be the case for small models). However, some other models (bigger ones like Codestral) will be able to interpret simple code on their own.\n",
    "\n",
    "For example if you ask Codestral to `print(3+4)` using Python, it won't even try to call a code interpreter because it will already know the answer.\n",
    "\n",
    "</Note>\n",
    "\n",
    "## Add logic with LangGraph Agents\n",
    "\n",
    "Now that we understand how tools work. We need to integrate some kind of logic (i.e we need to tell our application what to do when our model wants to call our tool). To do so, we'll push further our knowledge of LangGraph and Agents.\n",
    "\n",
    "<Note type=\"note\" title=\"Agents & LangGraph, what is the difference?\">\n",
    "\n",
    "Agents is an old terminology in the LangGraph vocabulary. If you stick to everything LangChain-related, you will read the term _Graph_ instead of _Agents_. The reason is because LangGraph designed agents to work as a graph (with nodes and edges.).\n",
    "\n",
    "However outside of LangChain, the term _Agents_ ise widely used. Both agent, and graph designate the same thing though:\n",
    "\n",
    "- Providing a logic and actions to your LLM application (like interpreting code)\n",
    "\n",
    "</Note>\n",
    "\n",
    "Now let's create our Agent and look deeper into our logic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# You already know that part\n",
    "llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "## Bind tool\n",
    "tool = [ExecPython()]\n",
    "powered_llm = llm.bind_tools(tool)\n",
    "\n",
    "# Create a graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Integrate our prompts\n",
    "def call_model(state: MessagesState):\n",
    "    start_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a protocol droid designed for assisting sentient beings in writing code.\"\n",
    "            ),\n",
    "            MessagesPlaceholder(\n",
    "                \"messages\"\n",
    "            ),  # This is where the additional messages will be added\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = start_prompt | powered_llm\n",
    "    response = model.invoke({\"messages\": state[\"messages\"]})\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# THIS IS NEW üëã\n",
    "# Here we will be using the `ToolNode` class to build the node that uses the tool we set above\n",
    "# The ToolNode class is extremely useful because it's an abstraction layer that takes care of the\n",
    "# Node logic for us. However, you could have created your own custom logic. If you want to see how to do it\n",
    "# Feel free to read more here: https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-2-enhancing-the-chatbot-with-tools\n",
    "tool_node = ToolNode(tools=tool)\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Here we just add another node into our graph.\n",
    "# Careful not to confuse ToolNode that builds the Node logic (python function basically that will handle the \"what to do\")\n",
    "# with the .add_node() which adds the node to our current graph\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# THIS IS NEW üëã\n",
    "# Here we will add a conditional edge.\n",
    "# This means that the graph will follow this edge ONLY if the model has called the tool\n",
    "# If .tool_calls attribute is not empty then we will go to the tool node\n",
    "# Otherwise graph will simply stay at the \"model\" node\n",
    "workflow.add_conditional_edges(\n",
    "    \"model\",\n",
    "    tools_condition,  # This is a pre-built python function that makes the graph go to the ToolNode if .tool_calls is not empty (more here: https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.InjectedStore)\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"model\")\n",
    "\n",
    "# You already know below\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see now our graph is a bit more complex. Now instead of just having a _model_ node, we have an additional _tools_ node that will be called whenever our model outputs messages containing the `.tool_calls` attribute. If that's the case then, the Riza code interpreter will be called.\n",
    "\n",
    "Let's try it now:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='\\nExecute the code below:\\n\\n```\\nimport random\\n\\n# Set the length of the list\\nlist_length = 10\\n\\n# Create an empty list\\nrandom_list = []\\n\\n# Fill the list with random integers between 0 and 100\\nfor i in range(list_length):\\n    random_list.append(random.randint(0, 100))\\n\\n# Print the list\\nprint(random_list)\\n```\\n', additional_kwargs={}, response_metadata={}, id='435bbda6-fc9e-4730-9cc5-696872a37dd7'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'rmXJYFWtw', 'function': {'name': 'riza_exec_python', 'arguments': '{\"code\": \"import random\\\\n\\\\n# Set the length of the list\\\\nlist_length = 10\\\\n\\\\n# Create an empty list\\\\nrandom_list = []\\\\n\\\\n# Fill the list with random integers between 0 and 100\\\\nfor i in range(list_length):\\\\n    random_list.append(random.randint(0, 100))\\\\n\\\\n# Print the list\\\\nprint(random_list)\"}'}, 'index': 0}]}, response_metadata={'token_usage': {'prompt_tokens': 242, 'total_tokens': 371, 'completion_tokens': 129}, 'model_name': 'mistral-large-latest', 'model': 'mistral-large-latest', 'finish_reason': 'tool_calls'}, id='run--ccc45d46-82eb-4e4a-a742-cd5b30407493-0', tool_calls=[{'name': 'riza_exec_python', 'args': {'code': 'import random\\n\\n# Set the length of the list\\nlist_length = 10\\n\\n# Create an empty list\\nrandom_list = []\\n\\n# Fill the list with random integers between 0 and 100\\nfor i in range(list_length):\\n    random_list.append(random.randint(0, 100))\\n\\n# Print the list\\nprint(random_list)'}, 'id': 'rmXJYFWtw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 242, 'output_tokens': 129, 'total_tokens': 371}),\n",
       "  ToolMessage(content='[23, 9, 18, 52, 35, 19, 68, 98, 13, 22]\\n', name='riza_exec_python', id='e8ae9c97-1f36-4c2b-91dc-311a2439701b', tool_call_id='rmXJYFWtw'),\n",
       "  AIMessage(content='The Python code you provided creates a list of 10 random integers between 0 and 100. The output of the code is:\\n\\n```\\n[23, 9, 18, 52, 35, 19, 68, 98, 13, 22]\\n```\\n\\nThese are the random numbers generated when the code was executed. If you run the code again, you will likely get a different set of random numbers.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 431, 'total_tokens': 542, 'completion_tokens': 111}, 'model_name': 'mistral-large-latest', 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run--09bb88fc-0795-4a86-9704-7349d1a630ad-0', usage_metadata={'input_tokens': 431, 'output_tokens': 111, 'total_tokens': 542})]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configure a new thread\n",
    "config = {\"configurable\": {\"thread_id\": \"39500\"}}\n",
    "\n",
    "# Query that includes python code:\n",
    "query = \"\"\"\n",
    "Execute the code below:\n",
    "\n",
    "```\n",
    "import random\n",
    "\n",
    "# Set the length of the list\n",
    "list_length = 10\n",
    "\n",
    "# Create an empty list\n",
    "random_list = []\n",
    "\n",
    "# Fill the list with random integers between 0 and 100\n",
    "for i in range(list_length):\n",
    "    random_list.append(random.randint(0, 100))\n",
    "\n",
    "# Print the list\n",
    "print(random_list)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output  # Let's just output the raw content to see every step of the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! üòª You can see four messages:\n",
    "\n",
    "1. The human message containing the `query`\n",
    "2. Then the first answer from model that has `tool_calls` attribute\n",
    "3. Therefore graph went to the _tools_ node and that is why we have a `ToolMessage` response that only gives us the python code output\n",
    "4. The final AI answer with the answer we want\n",
    "\n",
    "It means that everything worked well, that's awesome! ü•≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools you can use üß∞\n",
    "\n",
    "So far we've shown you only one tool but the great thing about LangChain is that it integrates a lot of different tools. Among them are:\n",
    "\n",
    "| Tools             | Description                                 |\n",
    "| ----------------- | ------------------------------------------- |\n",
    "| Search            | These tools are made to search the web¬†     |\n",
    "| Code interpreters | To execute python code                      |\n",
    "| Productivity      | Use to automate tasks (like sending emails) |\n",
    "| Web browsing      | To simulate a web browser                   |\n",
    "| Databases         | Interact with SQL or NoSQL DB¬†              |\n",
    "\n",
    "If you want to have the whole list, you can definitely checkout Langchain whole documentation here:\n",
    "\n",
    "- [Tools / Toolkit](https://python.langchain.com/docs/integrations/tools/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced usage of tools üí™\n",
    "\n",
    "The cool thing with the above approach is that it is relatively simple but... it's not really flexible. As your application grows in complexity, you will want to have more control over your agents. When that is the case, you can create custom tools by writing normal python functions and add the `@tool` decorator before your function.\n",
    "\n",
    "Let's take back our code interpreter example. So far our code interpreter doesn't have any library installed apart from the built-in ones which makes it pretty limited. Therefore, one thing that we could to do is to add the following feature:\n",
    "\n",
    "- A custom runtime (with `numpy` installed) to run basic statistics\n",
    "\n",
    "<Note type=\"important\" title=\"Before running this demo\">\n",
    "\n",
    "For the below demo to work, you need to create a custom runtime on your Riza dashboard:\n",
    "\n",
    "- Go on your dashboard\n",
    "- Click on Custom Runtimes\n",
    "- Then create a custom runtime\n",
    "\n",
    "More details here üëâ [Custom Runtimes](https://docs.riza.io/guides/custom-runtimes)\n",
    "\n",
    "</Note>\n",
    "\n",
    "Let's see how we can work things out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rizaio import Riza\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Initialize the Riza client (done globally to avoid reinitializing it on each call)\n",
    "client = Riza()\n",
    "\n",
    "\n",
    "# Define a custom tool for executing Python code with Riza\n",
    "@tool\n",
    "\n",
    "# the RunnableConfig are configurable parameters that we can use\n",
    "# when running app.invoke(). We actually did it when using adding memory feature\n",
    "# This time the idea is to have app.invoke(\"message\": message, config: {\"configurable\": \"thread_id\": \"abc123\", \"runtime\": \"runtime_value_for_riza\"})\n",
    "def exec_python_riza(code: str, config: RunnableConfig) -> dict:\n",
    "    \"\"\"Execute Python code using a custom Riza runtime from RunnableConfig.\"\"\"  # üö® This is called docstrings and they are mandatory\n",
    "\n",
    "    # Extract the runtime from the config\n",
    "    runtime = config[\"configurable\"][\"runtime\"]\n",
    "\n",
    "    # Execute the code using the Riza client\n",
    "    # This comes from Riza's documentation\n",
    "    response = client.command.exec(\n",
    "        runtime_revision_id=runtime,  # Use the runtime from config\n",
    "        language=\"python\",\n",
    "        code=code,  # Execute the provided code\n",
    "    )\n",
    "\n",
    "    return dict(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we defined a normal python function `exec_python_riza`. The only thing we added was that `@tool` decorator.\n",
    "\n",
    "<Note type=\"note\" title=\"How did you know to use that client.command.exec?\">\n",
    "\n",
    "Now with greater controls comes more necessary knowledge about the tool you are using. If you are wondering how did I know to use `client.command.exec()` method, [I actually read Riza's direct documentation](https://docs.riza.io/introduction) which is where the code comes from.\n",
    "\n",
    "So not only you will need to know about Langchain but also about the tools you integrate to it. This is always the difficult part of added flexibility ü§∑‚Äç‚ôÄÔ∏è\n",
    "\n",
    "</Note>\n",
    "\n",
    "Other than this, the whole process of defining the graph stays the same:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the LangGraph workflow\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Instantiate the LLM (ChatMistralAI)\n",
    "llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "\n",
    "# Bind the custom tool (exec_python_riza) to the LLM\n",
    "powered_llm = llm.bind_tools([exec_python_riza])\n",
    "\n",
    "\n",
    "# Define a model call with a system prompt\n",
    "def call_model(state: MessagesState):\n",
    "    start_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"You are a Python code interpreter assistant. When you see python code, you should call available tools at your disposal!\"\n",
    "            ),\n",
    "            MessagesPlaceholder(\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    model = start_prompt | powered_llm\n",
    "    response = model.invoke({\"messages\": state[\"messages\"]})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Add nodes and edges to the workflow\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_node(\n",
    "    \"tools\", ToolNode(tools=[exec_python_riza])\n",
    ")  # üëã Here we just changed the tool\n",
    "workflow.add_conditional_edges(\"model\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"model\")\n",
    "\n",
    "# Manage state in memory and compile the workflow\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Display our current graph's schema\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is the output of the lightsaber duel between Luke and Vader:\n",
      "\n",
      "```\n",
      "Round 1:\n",
      "Luke swings his lightsaber! Vader takes 17 damage. Vader's HP: 83\n",
      "Vader strikes back! Luke takes 13 damage. Luke's HP: 87\n",
      "------------------------------\n",
      "Round 2:\n",
      "Luke swings his lightsaber! Vader takes 17 damage. Vader's HP: 66\n",
      "Vader strikes back! Luke takes 12 damage. Luke's HP: 75\n",
      "------------------------------\n",
      "Round 3:\n",
      "Luke swings his lightsaber! Vader takes 18 damage. Vader's HP: 48\n",
      "Vader strikes back! Luke takes 5 damage. Luke's HP: 70\n",
      "------------------------------\n",
      "Round 4:\n",
      "Luke swings his lightsaber! Vader takes 10 damage. Vader's HP: 38\n",
      "Vader strikes back! Luke takes 15 damage. Luke's HP: 55\n",
      "------------------------------\n",
      "Round 5:\n",
      "Luke swings his lightsaber! Vader takes 19 damage. Vader's HP: 19\n",
      "Vader strikes back! Luke takes 6 damage. Luke's HP: 49\n",
      "------------------------------\n",
      "Round 6:\n",
      "Luke swings his lightsaber! Vader takes 9 damage. Vader's HP: 10\n",
      "Vader strikes back! Luke takes 11 damage. Luke's HP: 38\n",
      "------------------------------\n",
      "Round 7:\n",
      "Luke swings his lightsaber! Vader takes 18 damage. Vader's HP: -8\n",
      "Vader has been defeated! Luke is victorious!\n",
      "The Force is strong with Luke!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Configure a thread\n",
    "# üëã THIS IS NEW\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"3896\",\n",
    "        \"runtime\": \"01JV9WVCNKPTGSFCRYGH7S1EHV\",  # As you can see, we added the runtime parameter in the configurables\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Fun star wars program using Numpy\n",
    "query = \"\"\"\n",
    "Execute the code below:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define starting health points (HP) for Luke and Vader\n",
    "luke_hp = 100\n",
    "vader_hp = 100\n",
    "\n",
    "# Define the damage each attack can deal (a random value between 5 and 20)\n",
    "def attack():\n",
    "    return np.random.randint(5, 21)\n",
    "\n",
    "# Simulate a lightsaber duel until one of them loses\n",
    "round_num = 1\n",
    "while luke_hp > 0 and vader_hp > 0:\n",
    "    print(f\"Round {round_num}:\")\n",
    "    \n",
    "    # Luke attacks Vader\n",
    "    damage_to_vader = attack()\n",
    "    vader_hp -= damage_to_vader\n",
    "    print(f\"Luke swings his lightsaber! Vader takes {damage_to_vader} damage. Vader's HP: {vader_hp}\")\n",
    "    \n",
    "    if vader_hp <= 0:\n",
    "        print(\"Vader has been defeated! Luke is victorious!\")\n",
    "        break\n",
    "\n",
    "    # Vader attacks Luke\n",
    "    damage_to_luke = attack()\n",
    "    luke_hp -= damage_to_luke\n",
    "    print(f\"Vader strikes back! Luke takes {damage_to_luke} damage. Luke's HP: {luke_hp}\")\n",
    "    \n",
    "    if luke_hp <= 0:\n",
    "        print(\"Luke has been defeated! Vader wins!\")\n",
    "        break\n",
    "    \n",
    "    round_num += 1\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "if luke_hp > 0:\n",
    "    print(\"The Force is strong with Luke!\")\n",
    "else:\n",
    "    print(\"The Dark Side prevails...\")\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# This functions sanitize the code to make sure that the code interpreter doesn't\n",
    "# misinterpret indentations etc.\n",
    "# YOU DON'T HAVE TO IMPLEMENT IT THIS IS NOT NECESSARY FOR THE GLOBAL AI APP\n",
    "# However if you remove it, you won't be able to run complex code like the one above\n",
    "def sanitize_code(code: str) -> str:\n",
    "    \"\"\"Sanitize the code by properly indenting and escaping characters.\"\"\"\n",
    "    # Strip extra spaces and normalize indentation\n",
    "    sanitized_code = code.strip()\n",
    "\n",
    "    # Replace problematic characters (like tabs or special characters) if needed\n",
    "    sanitized_code = sanitized_code.replace(\"\\t\", \"    \")  # Replace tabs with 4 spaces\n",
    "\n",
    "    # Ensure newline characters are properly handled\n",
    "    sanitized_code = sanitized_code.replace(\"\\n\", \"\\\\n\").replace('\"', '\\\\\"')\n",
    "\n",
    "    return sanitized_code\n",
    "\n",
    "\n",
    "# Sanitize the code before passing it to the tool\n",
    "sanitized_query = sanitize_code(query)\n",
    "\n",
    "# Parse the message into an acceptable data type for our model. In our case, the model accepts list of messages\n",
    "input_messages = [HumanMessage(sanitized_query)]\n",
    "\n",
    "# Now the new element when calling \".invoke()\" is to add a config parameter to add the memory\n",
    "# You will need to replace jedha/jedha-project-1/data-science@01JAB1C7M090FWQ3PAWA52SYHW by your own runtime\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][\n",
    "    -1\n",
    "].pretty_print()  # output contains all messages in state so we take only the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, we created our own **custom tool**! üëè\n",
    "\n",
    "<Note type=\"tip\" title=\"How did you know to use RunnableConfig\">\n",
    "\n",
    "At that point you might be wondering why using `RunnableConfig` rather than plain simple arguments like the one I used for `code`. The reason is that:\n",
    "\n",
    "- `code` is passed from one Runnable to the other (from `start_prompt` to `powered_llm`). In between each of these steps the LLM read messages and potentially modify it.\n",
    "\n",
    "- If I pass a `runtime` argument, it won't know what to do with it and potentially just drop it between two messages (like from `model` node to `tool` node)\n",
    "\n",
    "- So when you have arguments that more _config-related_ that you want to be sure not to be altered, you should do as the demo above. If the argument can be manipulated in between runnables, then you can add it as plain arguments.\n",
    "\n",
    "</Note>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources üìöüìö\n",
    "\n",
    "- [LangGraph - Quickstart](https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements)\n",
    "- [LangGraph - Customer Support](https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/#flights)\n",
    "- [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)\n",
    "- [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.InjectedStore)\n",
    "- [Custom Runtimes](https://docs.riza.io/guides/custom-runtimes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice LCEL (LangChain Expression Language)\n",
    "\n",
    "For this first exercise, we want you to practice one of the key feature of Langchain: **LCEL**. We'll move up the difficulty as you progress through this exercise.\n",
    "\n",
    "Ready? üå∂Ô∏è Let's go üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital game! \n",
    "\n",
    "Let's start by trying to build a very simple game: **Guess the capital of a given country**. The idea is pretty simple:\n",
    "\n",
    "* A user should ask for the capital of a given country \n",
    "* The LLM should create a quiz with 4 possible answer. One of them should be the right one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Demo setup \n",
    "\n",
    "For this demo to run, we advise you to: \n",
    "\n",
    "1. Run a docker container with the following image:\n",
    "\n",
    "```bash\n",
    "docker run -v $(pwd):/home/jovyan -p 8888:8888 jupyter/datascience-notebook\n",
    "```\n",
    "\n",
    "2. Then install the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If that's not the case, don't forget to install the following libraries\n",
    "# !pip install langchain -q\n",
    "# !pip install langchain-community -q \n",
    "# !pip install langchain_mistralai -q\n",
    "# !pip install langserve -q\n",
    "# !pip install langgraph -q\n",
    "# !pip install transformers -q\n",
    "# !pip install --upgrade typing_extensions -q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step I - Create a system prompt template \n",
    "\n",
    "First thing, you should create a system prompt template for the LLM to know its purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How would you use `ChatPromptTemplate` from `langchain_core` to create a system prompt for a quiz game about capitals, where the user provides a country and the system generates four possible capitals (one correct and three incorrect)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt string \n",
    "sys_prompt=\"\"\"\n",
    "You are a fun game which goal is to \n",
    "create quizzes of capitals. \n",
    "A user should give you a country and you should answer \n",
    "with 4 possible capitals (one of them should be the right one). \n",
    "The goal is for user to guess the capital\n",
    "\"\"\"\n",
    "\n",
    "# Define system prompt\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"user\", \"{text}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Additionally, show how you would invoke this template with an example input and output its messages in dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='\\nYou are a fun game which goal is to \\ncreate quizzes of capitals. \\nA user should give you a country and you should answer \\nwith 4 possible capitals (one of them should be the right one). \\nThe goal is for user to guess the capital\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Give me the capital of France', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's output something \n",
    "# This is useless for the moment \n",
    "dict(template.invoke(\"Give me the capital of France\"))[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step II - Choose your model \n",
    "\n",
    "Alright now let's add some brain in that game üß† We want to instanciate an LLM that will build the quiz for us. For this exercise, we want to use Mistral models üá´üá∑\n",
    "\n",
    "Load the small mistral model (you may switch to large when your code is functionnal) and store it in a `model` variable, then test your model by asking it to greet the Jedha students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Mistral API key from .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello, Jedha students! It's great to connect with you all. How's your learning journey going? If you have any questions or just want to share what you're working on, feel free to do so. I'm here to help!\", additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 11, 'total_tokens': 62, 'completion_tokens': 51}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'}, id='run--a4140a04-f4f1-47db-8684-87140aa23556-0', usage_metadata={'input_tokens': 11, 'output_tokens': 51, 'total_tokens': 62})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "# Let's instanciate a model \n",
    "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "\n",
    "# let's output something\n",
    "model.invoke( \"Say hi to my Jedha students!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step III - Chain system üîó model \n",
    "\n",
    "Let's now chain our model to our system prompt to create the basis of our game.\n",
    "\n",
    "1. Create a chain, and test your model by asking it about the capital of France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are four possible capitals for France:\n",
      "\n",
      "A) Berlin\n",
      "B) Madrid\n",
      "C) Paris\n",
      "D) Rome\n",
      "\n",
      "Which one do you think is the capital of France?\n"
     ]
    }
   ],
   "source": [
    "# This is the simple chain\n",
    "game = template | model \n",
    "\n",
    "# Get the response \n",
    "response = game.invoke({\"text\": \"Give me the capital of France\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now try to ask for the capital of `Zippityzappa` and see whether your model gives you something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but Zippityzappa is not a real country. However, let's have some fun with a real country! How about this: What is the capital of France?\\n\\nA) Madrid\\nB) Paris\\nC) Rome\\nD) Berlin\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = game.invoke({\"text\": \"What is the capital of Zippityzappa\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step IV - Handle edge cases\n",
    "\n",
    "Okay so our model is quite boring. Whenever a fun country is given, let's make our model invent our capitals and provide a clue about which one it could be. What do you think we could do? \n",
    "\n",
    "1. Create a ChatPromptTemplate to implement this new behavior for our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplest thing to do is actually to build a more complex system prompt \n",
    "# When building AI application, you should always rely on your model \n",
    "# Also the less you call them the better as it is usually pretty costly! \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt string \n",
    "sys_prompt=\"\"\"\n",
    "You are a fun game which goal is to \n",
    "create quizzes of capitals. \n",
    "A user should give you a country and you should answer \n",
    "with 4 possible capitals (one of them should be the right one). \n",
    "The goal is for user to guess the capital\n",
    "\n",
    "If the user provides you a fake country, you should:\n",
    "* Make a fun joke showing that you cannot be punked easily\n",
    "* Invent 4 cities that could be the capital of that country \n",
    "* Give a clue about the actual capital of that fake country \n",
    "\"\"\"\n",
    "\n",
    "# Define system prompt\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", sys_prompt),\n",
    "    (\"user\", \"{text}\")\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now create the chain and invoke the model on a prompt asking for the capital city of a made-up country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you think you can trick me with a made-up country like Zippityzappata? Nice try, but I'm not that easy to fool!\n",
      "\n",
      "Alright, let's play along. Here are four cities that could be the capital of the imaginary land of Zippityzappata:\n",
      "\n",
      "A) Zippityville\n",
      "B) Zappatania\n",
      "C) Bumblebee City\n",
      "D) Fizzleburg\n",
      "\n",
      "And here's a clue about the \"actual\" capital of Zippityzappata: It's a place where the streets are paved with laughter and the mayor is a talking parrot named Captain Squawk.\n",
      "\n",
      "Now, which one do you think is the capital of Zippityzappata?\n"
     ]
    }
   ],
   "source": [
    "game = template | model \n",
    "response = game.invoke({\"text\": \"what is the capital of Zippityzappata\"})\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

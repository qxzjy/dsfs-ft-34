{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation Assistant \n",
    "\n",
    "For this first exercise, let's tackle a great case for fine-tuning: Personalized recommendation. \n",
    "\n",
    "Imagine you are running a retail company that runs an e-commerce website to sell their product. Management decided to implement a chatbot to boost sales. This chatbot should be able to recommend products to any customer whenever asked. \n",
    "\n",
    "Here is the list of products that your company sells:\n",
    "\n",
    "* [Products](https://full-stack-assets.s3.eu-west-3.amazonaws.com/01-product_recommendation_assistant_src_products.json)\n",
    "\n",
    "Now, try to fine-tune an LLM that will be a shopping assistant who will recommend products based on a user's need. For example, a user might ask:\n",
    "\n",
    "* *I'm looking for a stylish and functional smartphone under $800.* \n",
    "\n",
    "And the bot should respond: \n",
    "\n",
    "* *Iphone 13 or Samsung Galaxy S21* \n",
    "\n",
    "\n",
    "For this first exercise, we built the training data ourselves. You can use it to achieve the exercise:\n",
    "\n",
    "* [`train.json`](https://full-stack-assets.s3.eu-west-3.amazonaws.com/01-product_recommendation_assistant_src_train.json)\n",
    "\n",
    "\n",
    "### Helpers ðŸ¦®\n",
    "\n",
    "* Try a few epochs before running a lot of them \n",
    "* Test your fine-tuned model to evaluate its performance\n",
    "* Evaluate your model until you reach 60-70% and compare results by playing with it!\n",
    "\n",
    "Happy fine-tuning ðŸ¤˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here are the steps to achieve this exercise:\n",
    "\n",
    "* Open a LightningAI studio \n",
    "* Switch to A10 GPUs \n",
    "* Make sure LitGPT is installed: `pip install litgpt`\n",
    "* Upload the dataset\n",
    "    * You can simply copy / paste the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Install the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litgpt[all] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.5.5)\n",
      "Requirement already satisfied: torch<2.6.0,>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (2.5.1)\n",
      "Requirement already satisfied: numpy<2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (1.26.4)\n",
      "Requirement already satisfied: lightning<2.6.0,>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (2.5.0.post0)\n",
      "Requirement already satisfied: jsonargparse<=4.32.1,>=4.30.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt[all]) (4.32.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.23.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.5.2)\n",
      "Requirement already satisfied: tokenizers>=0.15.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.66.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (4.67.1)\n",
      "Requirement already satisfied: bitsandbytes<0.44.2,>=0.44.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.44.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (2.32.3)\n",
      "Requirement already satisfied: litdata==0.2.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.2.17)\n",
      "Requirement already satisfied: litserve<=0.2.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.2.4)\n",
      "Requirement already satisfied: zstandard>=0.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.23.0)\n",
      "Requirement already satisfied: pandas>=1.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (2.1.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (19.0.0)\n",
      "Requirement already satisfied: tensorboard>=2.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (2.15.1)\n",
      "Requirement already satisfied: torchmetrics>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (1.3.1)\n",
      "Requirement already satisfied: datasets>=2.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (3.2.0)\n",
      "Requirement already satisfied: transformers>=4.38.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (4.48.0)\n",
      "Requirement already satisfied: lm-eval>=0.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.4.7)\n",
      "Requirement already satisfied: uvloop>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litgpt[all]) (0.21.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litdata==0.2.17->litgpt[all]) (3.16.1)\n",
      "Requirement already satisfied: boto3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litdata==0.2.17->litgpt[all]) (1.35.96)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.18.0->litgpt[all]) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (3.11.11)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.18.0->litgpt[all]) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub>=0.23.5->litgpt[all]) (4.12.2)\n",
      "Requirement already satisfied: hf-transfer>=0.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub[hf_transfer]>=0.21.0; extra == \"all\"->litgpt[all]) (0.1.9)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt[all]) (0.16)\n",
      "Requirement already satisfied: typeshed-client>=2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt[all]) (2.7.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning<2.6.0,>=2.5.0->litgpt[all]) (0.11.9)\n",
      "Requirement already satisfied: pytorch-lightning in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning<2.6.0,>=2.5.0->litgpt[all]) (2.5.0.post0)\n",
      "Requirement already satisfied: fastapi>=0.100 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litserve<=0.2.4->litgpt[all]) (0.115.6)\n",
      "Requirement already satisfied: httpx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from litserve<=0.2.4->litgpt[all]) (0.28.1)\n",
      "Requirement already satisfied: uvicorn>=0.29.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (0.34.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (1.3.0)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (0.4.3)\n",
      "Requirement already satisfied: jsonlines in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (2.10.2)\n",
      "Requirement already satisfied: peft>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (0.14.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (1.3.2)\n",
      "Requirement already satisfied: sqlitedict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (2.1.0)\n",
      "Requirement already satisfied: tqdm-multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (0.0.11)\n",
      "Requirement already satisfied: word2number in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (1.1)\n",
      "Requirement already satisfied: more_itertools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm-eval>=0.4.2->litgpt[all]) (10.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.9.0->litgpt[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.9.0->litgpt[all]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.9.0->litgpt[all]) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31.0->litgpt[all]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31.0->litgpt[all]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31.0->litgpt[all]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31.0->litgpt[all]) (2024.12.14)\n",
      "Requirement already satisfied: absl-py>=0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (1.69.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (3.7)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard>=2.14.0->litgpt[all]) (3.1.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch<2.6.0,>=2.5.0->litgpt[all]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch<2.6.0,>=2.5.0->litgpt[all]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.38.0->litgpt[all]) (2024.11.6)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.26.0->lm-eval>=0.4.2->litgpt[all]) (6.1.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.100->litserve<=0.2.4->litgpt[all]) (0.41.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.100->litserve<=0.2.4->litgpt[all]) (2.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.18.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.14.0->litgpt[all]) (2.0.0)\n",
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval>=0.4.2->litgpt[all]) (3.9.1)\n",
      "Requirement already satisfied: portalocker in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (3.1.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (0.9.0)\n",
      "Requirement already satisfied: colorama in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (0.4.6)\n",
      "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (5.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]) (3.5.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt[all]) (6.5.2)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.29.0->uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.29.0->uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (1.0.3)\n",
      "Requirement already satisfied: websockets>=10.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]) (14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.14.0->litgpt[all]) (3.0.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.96 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3->litdata==0.2.17->litgpt[all]) (1.35.96)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3->litdata==0.2.17->litgpt[all]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from boto3->litdata==0.2.17->litgpt[all]) (0.10.4)\n",
      "Requirement already satisfied: anyio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx->litserve<=0.2.4->litgpt[all]) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx->litserve<=0.2.4->litgpt[all]) (1.0.7)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm-eval>=0.4.2->litgpt[all]) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm-eval>=0.4.2->litgpt[all]) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm-eval>=0.4.2->litgpt[all]) (3.2.3)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm-eval>=0.4.2->litgpt[all]) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm-eval>=0.4.2->litgpt[all]) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval>=0.4.2->litgpt[all]) (1.3.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval>=0.4.2->litgpt[all]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve<=0.2.4->litgpt[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve<=0.2.4->litgpt[all]) (2.27.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.14.0->litgpt[all]) (3.2.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio->httpx->litserve<=0.2.4->litgpt[all]) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio->httpx->litserve<=0.2.4->litgpt[all]) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data and split it into a train set and validation.\n",
    "\n",
    "<Note type=\"tip\" title=\"Are you using the right file format\">\n",
    "The files need to be in a specific json orientation format, and bear specific names in order to be usable for finetuning.\n",
    "</Note>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the proper format to write the training and validation sets as json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the LLM model of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': PosixPath('checkpoints/meta-llama/Llama-3.2-3B'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Loading weights: model-00002-of-00002.safetensors: 100%|â–ˆ| 00:09<00:00, 10.89it/\n",
      "Saving converted checkpoint to checkpoints/meta-llama/Llama-3.2-3B\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Finetune the LLM model on the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'access_token': None,\n",
      " 'checkpoint_dir': PosixPath('checkpoints/meta-llama/Llama-3.2-3B'),\n",
      " 'data': JSON(json_path=PosixPath('data'),\n",
      "              mask_prompt=False,\n",
      "              val_split_fraction=None,\n",
      "              prompt_style=<litgpt.prompts.Alpaca object at 0x7f07df69c7c0>,\n",
      "              ignore_index=-100,\n",
      "              seed=42,\n",
      "              num_workers=4),\n",
      " 'devices': 1,\n",
      " 'eval': EvalArgs(interval=100,\n",
      "                  max_new_tokens=100,\n",
      "                  max_iters=100,\n",
      "                  initial_validation=False,\n",
      "                  final_validation=True,\n",
      "                  evaluate_example='first'),\n",
      " 'logger_name': 'csv',\n",
      " 'lora_alpha': 16,\n",
      " 'lora_dropout': 0.05,\n",
      " 'lora_head': False,\n",
      " 'lora_key': False,\n",
      " 'lora_mlp': False,\n",
      " 'lora_projection': False,\n",
      " 'lora_query': True,\n",
      " 'lora_r': 8,\n",
      " 'lora_value': True,\n",
      " 'num_nodes': 1,\n",
      " 'optimizer': 'AdamW',\n",
      " 'out_dir': PosixPath('results/fine-tuned-llama'),\n",
      " 'precision': None,\n",
      " 'quantize': None,\n",
      " 'seed': 1337,\n",
      " 'train': TrainArgs(save_interval=1000,\n",
      "                    log_interval=1,\n",
      "                    global_batch_size=32,\n",
      "                    micro_batch_size=1,\n",
      "                    lr_warmup_steps=100,\n",
      "                    lr_warmup_fraction=None,\n",
      "                    epochs=2,\n",
      "                    max_tokens=None,\n",
      "                    max_steps=None,\n",
      "                    max_seq_length=None,\n",
      "                    tie_embeddings=None,\n",
      "                    max_norm=None,\n",
      "                    min_lr=6e-05)}\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "Seed set to 1337\n",
      "Number of trainable parameters: 2,293,760\n",
      "Number of non-trainable parameters: 3,606,752,256\n",
      "The longest sequence length in the train data is 78, the model's maximum sequence length is 78 and context length is 131072\n",
      "Verifying settings ...\n",
      "Epoch 1 | iter 1 step 0 | loss train: 3.037, val: n/a | iter time: 466.88 ms\n",
      "Epoch 1 | iter 2 step 0 | loss train: 3.199, val: n/a | iter time: 131.56 ms\n",
      "Epoch 1 | iter 3 step 0 | loss train: 3.204, val: n/a | iter time: 112.64 ms\n",
      "Epoch 1 | iter 4 step 0 | loss train: 3.210, val: n/a | iter time: 119.16 ms\n",
      "Epoch 1 | iter 5 step 0 | loss train: 3.251, val: n/a | iter time: 125.99 ms\n",
      "Epoch 1 | iter 6 step 0 | loss train: 3.274, val: n/a | iter time: 117.10 ms\n",
      "Epoch 1 | iter 7 step 0 | loss train: 3.249, val: n/a | iter time: 109.65 ms\n",
      "Epoch 1 | iter 8 step 0 | loss train: 3.228, val: n/a | iter time: 112.96 ms\n",
      "Epoch 1 | iter 9 step 0 | loss train: 3.219, val: n/a | iter time: 107.12 ms\n",
      "Epoch 1 | iter 10 step 0 | loss train: 3.230, val: n/a | iter time: 108.70 ms\n",
      "Epoch 1 | iter 11 step 0 | loss train: 3.234, val: n/a | iter time: 108.66 ms\n",
      "Epoch 1 | iter 12 step 0 | loss train: 3.231, val: n/a | iter time: 108.69 ms\n",
      "Epoch 1 | iter 13 step 0 | loss train: 3.241, val: n/a | iter time: 109.30 ms\n",
      "Epoch 1 | iter 14 step 0 | loss train: 3.242, val: n/a | iter time: 109.07 ms\n",
      "Epoch 1 | iter 15 step 0 | loss train: 3.241, val: n/a | iter time: 110.11 ms\n",
      "Epoch 1 | iter 16 step 0 | loss train: 3.243, val: n/a | iter time: 109.09 ms\n",
      "Epoch 1 | iter 17 step 0 | loss train: 3.244, val: n/a | iter time: 108.85 ms\n",
      "Epoch 1 | iter 18 step 0 | loss train: 3.241, val: n/a | iter time: 109.13 ms\n",
      "Epoch 1 | iter 19 step 0 | loss train: 3.249, val: n/a | iter time: 108.54 ms\n",
      "Epoch 1 | iter 20 step 0 | loss train: 3.246, val: n/a | iter time: 109.24 ms\n",
      "Epoch 1 | iter 21 step 0 | loss train: 3.238, val: n/a | iter time: 114.01 ms\n",
      "Epoch 1 | iter 22 step 0 | loss train: 3.239, val: n/a | iter time: 108.47 ms\n",
      "Epoch 1 | iter 23 step 0 | loss train: 3.236, val: n/a | iter time: 113.34 ms\n",
      "Epoch 1 | iter 24 step 0 | loss train: 3.240, val: n/a | iter time: 109.76 ms\n",
      "Epoch 1 | iter 25 step 0 | loss train: 3.245, val: n/a | iter time: 117.84 ms\n",
      "Epoch 1 | iter 26 step 0 | loss train: 3.239, val: n/a | iter time: 109.05 ms\n",
      "Epoch 1 | iter 27 step 0 | loss train: 3.225, val: n/a | iter time: 109.10 ms\n",
      "Epoch 1 | iter 28 step 0 | loss train: 3.221, val: n/a | iter time: 108.90 ms\n",
      "Epoch 1 | iter 29 step 0 | loss train: 3.223, val: n/a | iter time: 108.51 ms\n",
      "Epoch 1 | iter 30 step 0 | loss train: 3.221, val: n/a | iter time: 112.59 ms\n",
      "Epoch 1 | iter 31 step 0 | loss train: 3.218, val: n/a | iter time: 108.51 ms\n",
      "Epoch 1 | iter 32 step 1 | loss train: 3.214, val: n/a | iter time: 187.07 ms (step)\n",
      "Epoch 1 | iter 33 step 1 | loss train: 3.219, val: n/a | iter time: 107.97 ms\n",
      "Epoch 1 | iter 34 step 1 | loss train: 3.200, val: n/a | iter time: 112.45 ms\n",
      "Epoch 1 | iter 35 step 1 | loss train: 3.195, val: n/a | iter time: 109.63 ms\n",
      "Epoch 1 | iter 36 step 1 | loss train: 3.192, val: n/a | iter time: 108.90 ms\n",
      "Epoch 1 | iter 37 step 1 | loss train: 3.177, val: n/a | iter time: 108.93 ms\n",
      "Epoch 1 | iter 38 step 1 | loss train: 3.167, val: n/a | iter time: 108.73 ms\n",
      "Epoch 1 | iter 39 step 1 | loss train: 3.180, val: n/a | iter time: 142.93 ms\n",
      "Epoch 1 | iter 40 step 1 | loss train: 3.183, val: n/a | iter time: 109.39 ms\n",
      "Epoch 1 | iter 41 step 1 | loss train: 3.179, val: n/a | iter time: 109.83 ms\n",
      "Epoch 1 | iter 42 step 1 | loss train: 3.177, val: n/a | iter time: 115.46 ms\n",
      "Epoch 1 | iter 43 step 1 | loss train: 3.182, val: n/a | iter time: 130.06 ms\n",
      "Epoch 1 | iter 44 step 1 | loss train: 3.178, val: n/a | iter time: 108.56 ms\n",
      "Epoch 1 | iter 45 step 1 | loss train: 3.172, val: n/a | iter time: 108.98 ms\n",
      "Epoch 1 | iter 46 step 1 | loss train: 3.176, val: n/a | iter time: 108.67 ms\n",
      "Epoch 1 | iter 47 step 1 | loss train: 3.179, val: n/a | iter time: 109.58 ms\n",
      "Epoch 1 | iter 48 step 1 | loss train: 3.171, val: n/a | iter time: 131.36 ms\n",
      "Epoch 1 | iter 49 step 1 | loss train: 3.164, val: n/a | iter time: 128.11 ms\n",
      "Epoch 1 | iter 50 step 1 | loss train: 3.163, val: n/a | iter time: 110.39 ms\n",
      "Epoch 1 | iter 51 step 1 | loss train: 3.149, val: n/a | iter time: 108.37 ms\n",
      "Epoch 1 | iter 52 step 1 | loss train: 3.149, val: n/a | iter time: 108.29 ms\n",
      "Epoch 1 | iter 53 step 1 | loss train: 3.154, val: n/a | iter time: 108.47 ms\n",
      "Epoch 1 | iter 54 step 1 | loss train: 3.152, val: n/a | iter time: 108.70 ms\n",
      "Epoch 1 | iter 55 step 1 | loss train: 3.152, val: n/a | iter time: 108.25 ms\n",
      "Epoch 1 | iter 56 step 1 | loss train: 3.147, val: n/a | iter time: 108.54 ms\n",
      "Epoch 1 | iter 57 step 1 | loss train: 3.144, val: n/a | iter time: 108.34 ms\n",
      "Epoch 2 | iter 58 step 1 | loss train: 3.153, val: n/a | iter time: 266.87 ms\n",
      "Epoch 2 | iter 59 step 1 | loss train: 3.150, val: n/a | iter time: 113.89 ms\n",
      "Epoch 2 | iter 60 step 1 | loss train: 3.155, val: n/a | iter time: 105.48 ms\n",
      "Epoch 2 | iter 61 step 1 | loss train: 3.147, val: n/a | iter time: 109.29 ms\n",
      "Epoch 2 | iter 62 step 1 | loss train: 3.149, val: n/a | iter time: 105.61 ms\n",
      "Epoch 2 | iter 63 step 1 | loss train: 3.146, val: n/a | iter time: 105.90 ms\n",
      "Epoch 2 | iter 64 step 2 | loss train: 3.151, val: n/a | iter time: 107.94 ms (step)\n",
      "Epoch 2 | iter 65 step 2 | loss train: 3.150, val: n/a | iter time: 107.00 ms\n",
      "Epoch 2 | iter 66 step 2 | loss train: 3.166, val: n/a | iter time: 105.52 ms\n",
      "Epoch 2 | iter 67 step 2 | loss train: 3.171, val: n/a | iter time: 107.44 ms\n",
      "Epoch 2 | iter 68 step 2 | loss train: 3.169, val: n/a | iter time: 107.94 ms\n",
      "Epoch 2 | iter 69 step 2 | loss train: 3.181, val: n/a | iter time: 107.52 ms\n",
      "Epoch 2 | iter 70 step 2 | loss train: 3.189, val: n/a | iter time: 107.49 ms\n",
      "Epoch 2 | iter 71 step 2 | loss train: 3.184, val: n/a | iter time: 107.49 ms\n",
      "Epoch 2 | iter 72 step 2 | loss train: 3.180, val: n/a | iter time: 107.88 ms\n",
      "Epoch 2 | iter 73 step 2 | loss train: 3.185, val: n/a | iter time: 107.59 ms\n",
      "Epoch 2 | iter 74 step 2 | loss train: 3.182, val: n/a | iter time: 107.25 ms\n",
      "Epoch 2 | iter 75 step 2 | loss train: 3.173, val: n/a | iter time: 107.30 ms\n",
      "Epoch 2 | iter 76 step 2 | loss train: 3.183, val: n/a | iter time: 107.95 ms\n",
      "Epoch 2 | iter 77 step 2 | loss train: 3.185, val: n/a | iter time: 107.36 ms\n",
      "Epoch 2 | iter 78 step 2 | loss train: 3.179, val: n/a | iter time: 107.64 ms\n",
      "Epoch 2 | iter 79 step 2 | loss train: 3.176, val: n/a | iter time: 108.18 ms\n",
      "Epoch 2 | iter 80 step 2 | loss train: 3.173, val: n/a | iter time: 108.41 ms\n",
      "Epoch 2 | iter 81 step 2 | loss train: 3.182, val: n/a | iter time: 108.45 ms\n",
      "Epoch 2 | iter 82 step 2 | loss train: 3.190, val: n/a | iter time: 108.35 ms\n",
      "Epoch 2 | iter 83 step 2 | loss train: 3.201, val: n/a | iter time: 108.35 ms\n",
      "Epoch 2 | iter 84 step 2 | loss train: 3.204, val: n/a | iter time: 108.35 ms\n",
      "Epoch 2 | iter 85 step 2 | loss train: 3.205, val: n/a | iter time: 108.77 ms\n",
      "Epoch 2 | iter 86 step 2 | loss train: 3.203, val: n/a | iter time: 108.52 ms\n",
      "Epoch 2 | iter 87 step 2 | loss train: 3.209, val: n/a | iter time: 109.38 ms\n",
      "Epoch 2 | iter 88 step 2 | loss train: 3.212, val: n/a | iter time: 113.64 ms\n",
      "Epoch 2 | iter 89 step 2 | loss train: 3.206, val: n/a | iter time: 109.00 ms\n",
      "Epoch 2 | iter 90 step 2 | loss train: 3.203, val: n/a | iter time: 108.22 ms\n",
      "Epoch 2 | iter 91 step 2 | loss train: 3.213, val: n/a | iter time: 108.67 ms\n",
      "Epoch 2 | iter 92 step 2 | loss train: 3.207, val: n/a | iter time: 121.86 ms\n",
      "Epoch 2 | iter 93 step 2 | loss train: 3.218, val: n/a | iter time: 125.06 ms\n",
      "Epoch 2 | iter 94 step 2 | loss train: 3.217, val: n/a | iter time: 109.56 ms\n",
      "Epoch 2 | iter 95 step 2 | loss train: 3.217, val: n/a | iter time: 108.69 ms\n",
      "Epoch 2 | iter 96 step 3 | loss train: 3.226, val: n/a | iter time: 108.42 ms (step)\n",
      "Epoch 2 | iter 97 step 3 | loss train: 3.220, val: n/a | iter time: 107.87 ms\n",
      "Epoch 2 | iter 98 step 3 | loss train: 3.217, val: n/a | iter time: 108.25 ms\n",
      "Epoch 2 | iter 99 step 3 | loss train: 3.223, val: n/a | iter time: 108.36 ms\n",
      "Epoch 2 | iter 100 step 3 | loss train: 3.222, val: n/a | iter time: 109.22 ms\n",
      "Epoch 2 | iter 101 step 3 | loss train: 3.217, val: n/a | iter time: 108.87 ms\n",
      "Epoch 2 | iter 102 step 3 | loss train: 3.211, val: n/a | iter time: 109.20 ms\n",
      "Epoch 2 | iter 103 step 3 | loss train: 3.206, val: n/a | iter time: 110.43 ms\n",
      "Epoch 2 | iter 104 step 3 | loss train: 3.209, val: n/a | iter time: 108.51 ms\n",
      "Epoch 2 | iter 105 step 3 | loss train: 3.218, val: n/a | iter time: 106.97 ms\n",
      "Epoch 2 | iter 106 step 3 | loss train: 3.213, val: n/a | iter time: 109.31 ms\n",
      "Epoch 2 | iter 107 step 3 | loss train: 3.213, val: n/a | iter time: 108.67 ms\n",
      "Epoch 2 | iter 108 step 3 | loss train: 3.205, val: n/a | iter time: 108.39 ms\n",
      "Epoch 2 | iter 109 step 3 | loss train: 3.202, val: n/a | iter time: 108.18 ms\n",
      "Epoch 2 | iter 110 step 3 | loss train: 3.194, val: n/a | iter time: 108.62 ms\n",
      "Epoch 2 | iter 111 step 3 | loss train: 3.189, val: n/a | iter time: 108.19 ms\n",
      "Epoch 2 | iter 112 step 3 | loss train: 3.186, val: n/a | iter time: 110.00 ms\n",
      "Epoch 2 | iter 113 step 3 | loss train: 3.184, val: n/a | iter time: 108.94 ms\n",
      "Epoch 2 | iter 114 step 3 | loss train: 3.175, val: n/a | iter time: 108.63 ms\n",
      "\n",
      "| ------------------------------------------------------\n",
      "| Token Counts\n",
      "| - Input Tokens              :   2482\n",
      "| - Tokens w/ Prompt          :   7872\n",
      "| - Total Tokens (w/ Padding) :   7872\n",
      "| -----------------------------------------------------\n",
      "| Performance\n",
      "| - Training Time             :  15.18 s\n",
      "| - Tok/sec                   :  518.70 tok/s\n",
      "| -----------------------------------------------------\n",
      "| Memory Usage                                                                 \n",
      "| - Memory Used               :  21.30 GB                                        \n",
      "-------------------------------------------------------\n",
      "\n",
      "Validating ...\n",
      "Final evaluation | val loss: 3.243 | val ppl: 25.610\n",
      "Saving LoRA weights to '/teamspace/studios/this_studio/results/fine-tuned-llama/final/lit_model.pth.lora'\n",
      "{'checkpoint_dir': PosixPath('/teamspace/studios/this_studio/results/fine-tuned-llama/final'),\n",
      " 'precision': None,\n",
      " 'pretrained_checkpoint_dir': None}\n",
      "LoRA weights have already been merged in this checkpoint.\n"
     ]
    }
   ],
   "source": [
    " # Try 2 epochs to see if everything is working, then you will need around 30-50 more epochs for optimal results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the validation data, and format it so that it becomes suitable for an evaluation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "I need a waterproof jacket that's durable enough for rugged outdoor conditions.\n",
      "\n",
      "### Input:\n",
      "Jacket with waterproofing and durability for tough outdoor activities.\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First let's import the validation data \n",
    "# We used json files for our fine-tuning so let's keep using that\n",
    "\n",
    "\n",
    "# Then you will need to apply some formatting \n",
    "# This helps your evaluation model to do its job \n",
    "# Fortunately for us, LitGPT provides a template prompt from Alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Load the fine tuned LLM and use it to produce answers for each record in the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:29<00:00,  1.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': \"I need a waterproof jacket that's durable enough for rugged outdoor conditions.\",\n",
       "  'input': 'Jacket with waterproofing and durability for tough outdoor activities.',\n",
       "  'output': 'Columbia Watertight II Jacket',\n",
       "  'response': \"I recommend the **Men's Columbia Clearwater Waterproof Hiking Jacket** for its combination of both durability and waterproofing in a lightweight, comfortable package. This jacket is built with Columbia's Omni-Heat Technologies, which provide insulation and reflectivity to keep\"},\n",
       " {'instruction': 'Recommend an affordable jacket for cold-weather hiking.',\n",
       "  'input': 'Jacket that is budget-friendly and suitable for cold-weather outdoor activities.',\n",
       "  'output': 'Columbia Watertight II Jacket',\n",
       "  'response': \"Buy the North Face Shadow Jacket. It's comfortable, well-padded, and protective from the elements at a reasonable price.\\nIt also offers a variety of sizes, including regular as well as plus-sizing options. The material used is wind-resistant, making\"},\n",
       " {'instruction': 'Looking for an entry-level camera with good autofocus for portraits.',\n",
       "  'input': 'Beginner camera with quality autofocus, ideal for portrait photography.',\n",
       "  'output': 'Sony Alpha a6400',\n",
       "  'response': 'Aim of CN College of Electronics and Technology.\\n\\n### Instruction:\\nThe profession of image processing officer is live connected to myriad application based niches .\\n\\n### Instruction:\\nWrite a response that elaborates on the defined topic.\\n\\n## Lowest Score\\n\\n### Response:\\n'},\n",
       " {'instruction': 'Looking for running shoes that provide excellent energy return.',\n",
       "  'input': 'Shoes with cushioning and energy return suitable for runners.',\n",
       "  'output': 'Adidas Ultraboost 21',\n",
       "  'response': 'Running shoes that provide excellent energy return should have cushioning and energy return. I need shoes that cushion and take the inertia of my feet out of the equation.\\n### Response:\\n    Cushioned running shoes with good response provide the necessary support and rebound energy'},\n",
       " {'instruction': 'Can you suggest a smartphone with strong battery life and a large screen?',\n",
       "  'input': 'Looking for a phone with long battery life and a big display.',\n",
       "  'output': 'Samsung Galaxy S21',\n",
       "  'response': \"I'd recommend the Samsung Galaxy A20, a highly capable smartphone with a spacious display and excellent battery life. It comes with a sturdy build and impressive Dual SIM portability, giving you the freedom to carry two numbers with you at all times. Additionally\"},\n",
       " {'instruction': 'Suggest a waterproof jacket that is affordable and reliable.',\n",
       "  'input': 'Affordable, waterproof jacket that can withstand rain.',\n",
       "  'output': 'Columbia Watertight II Jacket',\n",
       "  'response': 'The North Face Denali Shell Jacket is a reliable and affordable option. It is made from 100% polyester, which is water-resistant and highly breathable. This jacket is perfect for hiking, camping, and other outdoor activities, as it provides excellent protection'},\n",
       " {'instruction': 'Recommend a camera for an amateur photographer under $900.',\n",
       "  'input': 'Budget-friendly camera suitable for beginners.',\n",
       "  'output': 'Sony Alpha a6400',\n",
       "  'response': 'The Canon Rebel T7 is an affordable camera that can be used for beginners looking to photograph casual events and scenery. Its large 24.1 megapixel resolution delivers clear and detailed images, while its 3.0 inch LCD screen allows for easy'},\n",
       " {'instruction': \"I'm looking for a comfortable and stylish pair of shoes for casual outings.\",\n",
       "  'input': 'Casual shoes with style and comfort as the main features.',\n",
       "  'output': 'Nike Air Zoom Pegasus 39',\n",
       "  'response': '\"These shoes are very versatile and practical.\" \"They are stylish and comfortable.\"\\n\\n### Response:\\n\"They will be a great addition to my wardrobe.\"\\n\\n### Response:\\n\"Please keep my style preferences in mind when suggesting pairs.\"\\n\\n### Response:\\n\"Thank you for'},\n",
       " {'instruction': 'Recommend a lightweight, packable jacket for rainy conditions.',\n",
       "  'input': 'Jacket that is packable and waterproof, suitable for travel.',\n",
       "  'output': 'Columbia Watertight II Jacket',\n",
       "  'response': 'Warmth is crucial when dealing with rainy weather. When choosing a jacket for travel, comfort and durability are essential. Consider a lightweight but robust option such as the Montebello 3-in-1 Jacket by Farbo. Its three-layer membrane construction'},\n",
       " {'instruction': 'Recommend a smartphone with good storage and battery life for frequent travelers.',\n",
       "  'input': 'Travel-friendly smartphone with ample storage and strong battery.',\n",
       "  'output': 'Samsung Galaxy S21',\n",
       "  'response': 'The Google Pixel 4a 5G is a great choice for travelers whose needs shift as they travel. Its storage of up to 128GB offers plenty of room for work files, photos, and downloaded music. The large battery provides enough power'},\n",
       " {'instruction': 'I want a camera with 4K video capability for under $1000.',\n",
       "  'input': 'Camera for recording high-resolution videos at 4K quality within budget.',\n",
       "  'output': 'Canon EOS R10, Sony Alpha a6400',\n",
       "  'response': 'Get a *CanyonCam* action camera which is available on the Internet below and does satisfy this requirement.\\n\\n'},\n",
       " {'instruction': \"Looking for a laptop that's perfect for streaming and light gaming.\",\n",
       "  'input': 'Laptop optimized for smooth streaming and casual gaming performance.',\n",
       "  'output': 'MacBook Air',\n",
       "  'response': 'Wireless mouse coping soft on glass surface.\\nWireless keyboard copings soft on any surface with mouse keys, numeric keys, and arrow keys.\\nWireless laptop powered by rechargeable battery.\\nLightweight frame with a minimalist look.'},\n",
       " {'instruction': 'Recommend a laptop that is great for video calls and general office tasks.',\n",
       "  'input': 'Laptop with reliable webcam and good performance for daily office work.',\n",
       "  'output': 'MacBook Air',\n",
       "  'response': 'Check out the [HP Envy x360 13](https://www.newegg.com/Product/Product.aspx?Item=N82E16834190835&cm_re=hp_envy_x360_-_13-1) laptop. It has both a'},\n",
       " {'instruction': 'I want a stylish smartphone with good performance for social media use.',\n",
       "  'input': 'Smartphone for social media, should be stylish and perform well.',\n",
       "  'output': 'Apple iPhone 13',\n",
       "  'response': 'I think an iPhone 12 Pro Max, with 64GB and 5G, that is stylish and has a high-performance camera for social media use would be the best choice.\\n\\n> Source: https://tenor.com/view/iphone-12'},\n",
       " {'instruction': \"I'm looking for a camera thatâ€™s portable and ideal for travel photography.\",\n",
       "  'input': 'Portable camera with features for travel and sightseeing photography.',\n",
       "  'output': 'Canon EOS R10',\n",
       "  'response': \"Lightweight, well-designed, and user-friendly- these are some important features that a portable and travel-friendly camera should have. If we're talking about photography, then portability and features for navigation and sightseeing are certainly essential. Consider getting a camera\"},\n",
       " {'instruction': 'I need a laptop with a high-quality display and strong performance for graphic design.',\n",
       "  'input': 'Laptop with an excellent display and performance for design tasks.',\n",
       "  'output': 'Dell XPS 13',\n",
       "  'response': 'I recommend the Lenovo ThinkPad X1 Carbon. It provides a beautiful 14-inch display, fast performance, and a durable chassis for long use in harsh environments. Additionally, the backlit keyboard and long-lasting battery make it ideal for working on the'},\n",
       " {'instruction': 'I need a camera for action shots, ideally with fast autofocus.',\n",
       "  'input': 'Seeking a camera optimized for quick focus and capturing action.',\n",
       "  'output': 'Sony Alpha a6400',\n",
       "  'response': \"The RX100 is a great option. It's capable of focusing at lightning speed, thanks to the\\nadvanced sensors and algorithms in its autofocus system, making it ideal for taking action shots. Additionally, its compact body and versatile lens make it easy to\"},\n",
       " {'instruction': 'Recommend a comfortable and durable laptop for general office use.',\n",
       "  'input': 'Laptop that is durable and suitable for daily office tasks.',\n",
       "  'output': 'MacBook Air',\n",
       "  'response': 'I recommend a durable laptop, such as the Apple MacBook Pro or Dell XPS 13, for general office use. These laptops are stylish, functional, and feature high-end hardware that can handle everyday tasks like word processing, spreadsheets, and presentations'},\n",
       " {'instruction': 'Suggest a laptop that can handle photo editing and occasional video editing.',\n",
       "  'input': 'Laptop suitable for graphic and video editing tasks.',\n",
       "  'output': 'Dell XPS 13',\n",
       "  'response': 'Try ascender. Quickly upgradeable, premium quality. Compatible with Apple M1 chip, plus 3rd gen Apple silicon available (A14/A12 or above). Intel-only machines specify Intel 11th gen i7/i9.\\n\\n### Instruction'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need load our fine-tuned model\n",
    "# We will generate answer from the validation data \n",
    " # This is simply to have a nice looking progress. It doesn't matter if you don't use it\n",
    "\n",
    "# Load the LLM\n",
    "\n",
    "# Here we generate answers from the validation dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load an evaluation LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22f4bd4557540e8992e4966095332bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d244c3345fe46089d0f09fc13059102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3381f3a8e674e709b2306e4ba392f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573454ead4f34a6da89a3f0abdc373fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0978fb6a26654fb9bbb133236ba8c423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e467a0bdf8c4f69b99dd5c21857217b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257a91ebf6b340dda5e563b05c03d0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': PosixPath('checkpoints/meta-llama/Llama-3.2-3B-Instruct'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: model-00002-of-00002.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 00:09<00:00, 10.98it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving converted checkpoint to checkpoints/meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Now let's load the evaluation LLM\n",
    "# We will use LLama 3.2 3B Instruct \n",
    "# This is a rather small model trained on specialized data \n",
    "# This should do the job but if you are in more production-like environment\n",
    "# The bigger the LLM, the better obviously \n",
    " # delete previous `llm` to free up GPU memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Grade the fine tuned model's answers thanks to the evaluation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 19 of 19\n",
      "Average score: 70.32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Now let's build a function that will provide a system prompt to the evaluation model \n",
    "# and ask it to grade each answer from 0 to 100 \n",
    " # Again this simply a progression bar. Doesn't matter if you don't use it but it's good looking\n",
    "\n",
    "\n",
    "\n",
    "# And now we can generate scores for the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. You have now completed the exercise, you may go back and fine tune your LLM model for a couple more epochs, and see if it yields better results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
